{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks - Building a model to predict whether a customer will buy again or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "\n",
    "* Preprocess the data\n",
    "* Balance the dataset\n",
    "* Create training, validation and test datasets\n",
    "* Save the data in npz format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.loadtxt('data/Audiobooks_data.csv', delimiter = ',')\n",
    "\n",
    "# Inputs\n",
    "raw_inputs = raw_data[:,1:-1]\n",
    "# Output\n",
    "raw_output = raw_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Balancing the dataset\n",
    "\n",
    "* There are way more zeros than ones in output column.\n",
    "* The problem is that you could achieve a whopping ~84% accuracy by always predicting 0\n",
    "* This could be problematic and requires balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11847, 2237)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw_output == 0).sum(), (raw_output == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero indices\n",
    "indices_zero = np.where(raw_output == 0)[0]\n",
    "# One indices\n",
    "indices_one = np.where(raw_output == 1)[0]\n",
    "\n",
    "# Chosen random zero indices\n",
    "chosen_indices_zero = np.random.choice(indices_zero, size = len(indices_one), replace = False)\n",
    "\n",
    "# Concatenate chosen zero indices and one indices\n",
    "balanced_indices = np.concatenate((indices_one, chosen_indices_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4474,)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced output\n",
    "balanced_output = raw_output[balanced_indices]\n",
    "balanced_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4474, 10)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced input\n",
    "balanced_input = raw_inputs[balanced_indices]\n",
    "balanced_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2237, 2237)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(balanced_output == 0).sum(), (balanced_output == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = preprocessing.scale(balanced_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling of indices\n",
    "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "# Shuffled inputs and output\n",
    "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
    "shuffled_output = balanced_output[shuffled_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4474"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count all\n",
    "samples_count = shuffled_inputs.shape[0]\n",
    "samples_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3579"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training 0.8 * all\n",
    "train_count = int(0.8*samples_count)\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation 0.1 * all\n",
    "validation_count = int(0.1*samples_count)\n",
    "validation_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test = all - train + validation\n",
    "test_count = samples_count - train_count - validation_count\n",
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train inputs and output\n",
    "train_inputs = shuffled_inputs[:train_count]\n",
    "train_output = shuffled_output[:train_count]\n",
    "\n",
    "# Validation inputs and output\n",
    "validation_inputs = shuffled_inputs[train_count: train_count+validation_count]\n",
    "validation_output = shuffled_output[train_count: train_count+validation_count]\n",
    "\n",
    "# Test inputs and output\n",
    "test_inputs = shuffled_inputs[train_count+validation_count:]\n",
    "test_output = shuffled_output[train_count+validation_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3579, 10), (447, 10), (448, 10))"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape,validation_inputs.shape, test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3579,), (447,), (448,))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output.shape, validation_output.shape, test_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save npzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train npz\n",
    "np.savez('npz/Audiobooks_data_train', inputs = train_inputs, output = train_output)\n",
    "# Validation npz\n",
    "np.savez('npz/Audiobooks_data_validation', inputs = validation_inputs, output = validation_output)\n",
    "# Test npz\n",
    "np.savez('npz/Audiobooks_data_test', inputs = test_inputs, output = test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data\n",
    "\n",
    "* (We already have the data but oh well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load npzs\n",
    "npz_train = np.load('npz/Audiobooks_data_train.npz')\n",
    "npz_validation = np.load('npz/Audiobooks_data_validation.npz')\n",
    "npz_test = np.load('npz/Audiobooks_data_test.npz')\n",
    "\n",
    "# Unload npzs\n",
    "train_inputs = npz_train['inputs'].astype(float)\n",
    "train_output = npz_train['output'].astype(int)\n",
    "\n",
    "validation_inputs = npz_validation['inputs'].astype(float)\n",
    "validation_output = npz_validation['output'].astype(int)\n",
    "\n",
    "test_inputs = npz_test['inputs'].astype(float)\n",
    "test_output = npz_test['output'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 2\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # 2 hidden layers\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitors val_loss and restores the weights for best validation loss\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                                  patience = 3,\n",
    "                                                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 1s 4ms/step - loss: 0.5704 - accuracy: 0.7010 - val_loss: 0.4827 - val_accuracy: 0.7785\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7670 - val_loss: 0.4116 - val_accuracy: 0.7897\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7804 - val_loss: 0.3843 - val_accuracy: 0.7919\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.7907 - val_loss: 0.3660 - val_accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.7921 - val_loss: 0.3611 - val_accuracy: 0.8121\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8025 - val_loss: 0.3548 - val_accuracy: 0.8098\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8069 - val_loss: 0.3537 - val_accuracy: 0.8054\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8103 - val_loss: 0.3485 - val_accuracy: 0.8143\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8094 - val_loss: 0.3500 - val_accuracy: 0.8143\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8100 - val_loss: 0.3484 - val_accuracy: 0.8143\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8125 - val_loss: 0.3576 - val_accuracy: 0.8054\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3559 - accuracy: 0.8131 - val_loss: 0.3404 - val_accuracy: 0.8076\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8086 - val_loss: 0.3389 - val_accuracy: 0.8076\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8122 - val_loss: 0.3399 - val_accuracy: 0.8188\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8167 - val_loss: 0.3503 - val_accuracy: 0.8031\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8161 - val_loss: 0.3454 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x179b86e2fe0>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_inputs,\n",
    "          train_output,\n",
    "          batch_size=batch_size,\n",
    "          epochs = max_epochs,\n",
    "          callbacks = [early_stopping],\n",
    "          validation_data = (validation_inputs, validation_output),\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 767us/step - loss: 0.3429 - accuracy: 0.8259\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.34\n",
      "Test accuracy: 82.59%\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {0:.2f}\\nTest accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 82.59% Accuracy\n",
    "\n",
    "* Decent but was honestly hoping for >90% accuracy. Might do some finetuning later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
